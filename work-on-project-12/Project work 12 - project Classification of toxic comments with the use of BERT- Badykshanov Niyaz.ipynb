{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация токсичных комментариев с применением BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно построить инструмент, который будет искать токсичные комментарии.\n",
    "\n",
    "Обучим модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Для генерации фичей примененим BERT. Желательно достигнуть метрики F1 не меньше 0.75 \n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортирование необходимых модулей и атрибутов\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "\n",
    "from numba import cuda\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords \n",
    "import transformers as ppb\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "from tqdm import notebook\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.model_selection import cross_val_score\n",
    "#from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим вспомогательные переменные, константы\n",
    "SEED = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объявим функцию, которая будет читать файлы\n",
    "def pth_load(pth1, pth2):\n",
    "    \"\"\"Sapport using os.path.exists. Load local file in primarily\n",
    "\n",
    "    :param pth1: local addres of file\n",
    "    :type pth1: object\n",
    "    :param pth2: external addres of file\n",
    "    :type pth2: object\n",
    "    \n",
    "    :raises ValueError: if file not found in addresses\n",
    "    \n",
    "    :rtype: DataFrame\n",
    "    :return: foundly file in the form of DataFrame\n",
    "    \"\"\"\n",
    "    if os.path.exists(pth1):\n",
    "        df = pd.read_csv(pth1)\n",
    "    elif os.path.exists(pth2):\n",
    "        df = pd.read_csv(pth2)\n",
    "    else:\n",
    "        print('Something is wrong')\n",
    "    return df\n",
    "\n",
    "# Прочитаем файл, сохраним данные\n",
    "df = pth_load('toxic_comments.csv', '/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вызовем метод 'info()' и напечатаем несколько строк. Прочитаем одну строку целиком\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Прочитаем одну строку целиком\n",
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Напишем функцию для очистки текста\n",
    "def clear_text(text):\n",
    "    \"\"\"performs cleans the text\n",
    "\n",
    "    :param text: text to clear\n",
    "    :type text: object\n",
    "    \n",
    "    :rtype: object\n",
    "    :return: cleared text\n",
    "    \"\"\"\n",
    "    text = re.sub(r'[^a-z\\' ^0-9]', ' ', text)\n",
    "    #text = re.sub(r'[^a-z]', ' ', text)\n",
    "    clean_text = \" \".join(text.split())\n",
    "    \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переведем символы в нижний регистр\n",
    "df['lemm_text'] = df['text'].str.lower()\n",
    "\n",
    "# Обрежем текст ячеек от лишних символов\n",
    "df['lemm_text'] = df['lemm_text'].apply(lambda x: clear_text(x))\n",
    "\n",
    "#df['lemm_text'] = df['lemm_text'].str.slice(0, 512) # можно обрезать ячейки до 512 символов в случае необходимости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы ускорить лемматизацию, объединим ячейки и вызовем функцию лемматизации к объединенной строке. Проблема в том, что многие функции лемматизации, например Mystem, при каждом вызове загружается заново, сильно замедляя процесс. Также можно применить распараллеливание процесса.\n",
    "\n",
    "В данном случае мы используем WordNetLemmatizer, работающий с английским языком, но в рамках учебного процесса оставим этот метод.\n",
    "Данный метод был описан на странице https://itnan.ru/post.php?c=1&p=503420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сколько ячеек объединяем в одну\n",
    "batch_size = 1000\n",
    "\n",
    "text_batch = [list(df['lemm_text'])[i: i + batch_size] for i in range(0, len(df), batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:40<00:00,  3.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# Лемматизируем объединенные ячейки и разделим обратно на отдельные\n",
    "def checkExecTimeMystemOneText(texts):\n",
    "    \"\"\"performs lemmatization the text. first it combines the text for joint processing, at the end it separates\n",
    "\n",
    "    :param text: text to lemmatization\n",
    "    :type text: object\n",
    "    \n",
    "    :rtype: object\n",
    "    :return: lemmatized text\n",
    "    \"\"\"\n",
    "    #m = Mystem()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    lol = lambda lst, sz: [lst[i:i+sz] for i in range(0, len(lst), sz)]\n",
    "    txtpart = lol(texts, batch_size)\n",
    "    res = []\n",
    "    for txtp in txtpart:\n",
    "        alltexts = ' '.join([txt + ' brblm ' for txt in txtp])\n",
    "        \n",
    "        #words = m.lemmatize(alltexts)\n",
    "        words = [lemmatizer.lemmatize(w) for w in nltk.word_tokenize(alltexts)]\n",
    "        \n",
    "        doc = []\n",
    "        for txt in words:\n",
    "            if txt != '\\n' and txt.strip() != '':\n",
    "                if txt == 'brblm':\n",
    "                    res.append(doc)\n",
    "                    doc = []\n",
    "                else:\n",
    "                    doc.append(txt)\n",
    "                    \n",
    "        return res\n",
    "\n",
    "processed_texts = Parallel(n_jobs=-1)(delayed(checkExecTimeMystemOneText)(t) for t in tqdm(text_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   text       159571 non-null  object\n",
      " 1   toxic      159571 non-null  int64 \n",
      " 2   lemm_text  159571 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 3.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww he match this background colour i 'm see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i 'm really not trying to edit war it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i ca n't make any real suggestion on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  explanation why the edits made under my userna...  \n",
       "1  d'aww he match this background colour i 'm see...  \n",
       "2  hey man i 'm really not trying to edit war it ...  \n",
       "3  more i ca n't make any real suggestion on impr...  \n",
       "4  you sir are my hero any chance you remember wh...  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получился вложенный список. Развернем верхний слой и объединим список в текст\n",
    "lemm_text = sum(processed_texts, [])\n",
    "\n",
    "# Удалим использованные переменные\n",
    "del text_batch\n",
    "del processed_texts\n",
    "\n",
    "for i in range(0, len(lemm_text), 1):\n",
    "    lemm_text[i] = \" \".join(lemm_text[i]).replace(' \\' ','\\'')\n",
    "\n",
    "# Сохраним в набор данных\n",
    "df['lemm_text'] = lemm_text\n",
    "del lemm_text\n",
    "\n",
    "# Проверим результат\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До этого момента код был аналогичен проекту без использования берта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131014</th>\n",
       "      <td>Just updated. SRS won 4, and not 5.</td>\n",
       "      <td>0</td>\n",
       "      <td>just updated sr won 4 and not 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5442</th>\n",
       "      <td>\"\\n\\nThis article is being rewritten at Jack A...</td>\n",
       "      <td>0</td>\n",
       "      <td>this article is being rewritten at jack abramo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83578</th>\n",
       "      <td>Again, you don't decide what NPOV means! When ...</td>\n",
       "      <td>0</td>\n",
       "      <td>again you do n't decide what npov mean when yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47505</th>\n",
       "      <td>Listen... \\n\\n...I've been vandalising for eig...</td>\n",
       "      <td>0</td>\n",
       "      <td>listen i 've been vandalising for eight year i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144099</th>\n",
       "      <td>My long-term memory may be failing me. It was ...</td>\n",
       "      <td>0</td>\n",
       "      <td>my long term memory may be failing me it wa me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139899</th>\n",
       "      <td>which may contain more details</td>\n",
       "      <td>0</td>\n",
       "      <td>which may contain more detail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17760</th>\n",
       "      <td>that is so significant and of such consequence</td>\n",
       "      <td>0</td>\n",
       "      <td>that is so significant and of such consequence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127779</th>\n",
       "      <td>PS: in WP it is mentioned here: Idaho_National...</td>\n",
       "      <td>0</td>\n",
       "      <td>p in wp it is mentioned here idaho national la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>Evan Rachel Wood\\nIs there any evidence that s...</td>\n",
       "      <td>0</td>\n",
       "      <td>evan rachel wood is there any evidence that sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33369</th>\n",
       "      <td>July 2007 (UTC); Updated. NYScholar 20:28, 26</td>\n",
       "      <td>0</td>\n",
       "      <td>july 2007 utc updated nyscholar 20 28 26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "131014                Just updated. SRS won 4, and not 5.      0   \n",
       "5442    \"\\n\\nThis article is being rewritten at Jack A...      0   \n",
       "83578   Again, you don't decide what NPOV means! When ...      0   \n",
       "47505   Listen... \\n\\n...I've been vandalising for eig...      0   \n",
       "144099  My long-term memory may be failing me. It was ...      0   \n",
       "...                                                   ...    ...   \n",
       "139899                     which may contain more details      0   \n",
       "17760      that is so significant and of such consequence      0   \n",
       "127779  PS: in WP it is mentioned here: Idaho_National...      0   \n",
       "1134    Evan Rachel Wood\\nIs there any evidence that s...      0   \n",
       "33369       July 2007 (UTC); Updated. NYScholar 20:28, 26      0   \n",
       "\n",
       "                                                lemm_text  \n",
       "131014                    just updated sr won 4 and not 5  \n",
       "5442    this article is being rewritten at jack abramo...  \n",
       "83578   again you do n't decide what npov mean when yo...  \n",
       "47505   listen i 've been vandalising for eight year i...  \n",
       "144099  my long term memory may be failing me it wa me...  \n",
       "...                                                   ...  \n",
       "139899                      which may contain more detail  \n",
       "17760      that is so significant and of such consequence  \n",
       "127779  p in wp it is mentioned here idaho national la...  \n",
       "1134    evan rachel wood is there any evidence that sh...  \n",
       "33369            july 2007 utc updated nyscholar 20 28 26  \n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вычисления всего датасета даже с использованием видеокарты будет проводиться несколько часов, поэтому ограничим выборку\n",
    "exampl_lemm = df.sample(50000)\n",
    "exampl_lemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Загрузка предобученной модели/токенизатора \n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Будем проводить вычисления на GPU\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем токенайзеры и паддинги\n",
    "tokenized = exampl_lemm['lemm_text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, padding=True, truncation=True)))\n",
    "\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape\n",
    "\n",
    "padded = torch.tensor(padded).to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19beb94c6b9b41da88ab14b80c44ea40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(50000, 768)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Генерируем фичи \n",
    "batch_size = 10 # для примера возьмем такой батч\n",
    "embeddings = [] \n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "    batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]).cuda() # закидываем тензор на GPU\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.cuda()\n",
    "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "    embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy()) # перевод обратно на CPU чтобы сохранить в numpy\n",
    "    del batch\n",
    "    del attention_mask_batch\n",
    "    del batch_embeddings\n",
    "\n",
    "features = np.concatenate(embeddings) \n",
    "\n",
    "# Проверим результат\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Генерируем таргеты, т.е. целевые признаки\n",
    "target = exampl_lemm['toxic']\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим полученные выборки на тренировочную и тестовую\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, \n",
    "                                                                            target, \n",
    "                                                                            test_size=0.2, \n",
    "                                                                            random_state=SEED\n",
    "                                                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы успешно получили тренировочные и тестовые фачи и целевые признаки, теперь можно обучить любую модель для генерации предсказания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель логистической регрессии и посмотрим на метрику F1. Подбирать гиперпараметры не будем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучим модель и сгенерируем предсказания\n",
    "logistic_model = LogisticRegression(random_state=SEED, max_iter=2000)\n",
    "logistic_model.fit(features_train, target_train)\n",
    "predictions = logistic_model.predict(features_test)\n",
    "predictions = pd.Series(predictions, index = target_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика f1: 0.687\n"
     ]
    }
   ],
   "source": [
    "# Посчитаем целевую метрику и выведем не экран\n",
    "accuracy = f1_score(target_test, predictions)\n",
    "print('Метрика f1: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы использовали BERT для генерации фичей из лемматизированной строки, и моделью логистической регрессии предсказали принадлежность строки к одному из двух категорий: токсичная и нетоксичная. Модель на тестовой выбоке показала метрику F1 в 0.687. Неплохой результат, это больше, чем большинство моделей в проекте \"Классификация токсичности комментариев\" (без применения BERT)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
