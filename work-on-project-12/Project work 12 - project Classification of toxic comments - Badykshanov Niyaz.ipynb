{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация токсичных комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно построить инструмент, который будет искать токсичные комментарии.\n",
    "\n",
    "Обучим модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Построим модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортирование необходимых модулей и атрибутов\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import lightgbm\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим вспомогательные переменные, константы\n",
    "SEED = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объявим функцию, которая будет читать файлы\n",
    "def pth_load(pth1, pth2):\n",
    "    \"\"\"Sapport using os.path.exists. Load local file in primarily\n",
    "\n",
    "    :param pth1: local addres of file\n",
    "    :type pth1: object\n",
    "    :param pth2: external addres of file\n",
    "    :type pth2: object\n",
    "    \n",
    "    :raises ValueError: if file not found in addresses\n",
    "    \n",
    "    :rtype: DataFrame\n",
    "    :return: foundly file in the form of DataFrame\n",
    "    \"\"\"\n",
    "    if os.path.exists(pth1):\n",
    "        df = pd.read_csv(pth1)\n",
    "    elif os.path.exists(pth2):\n",
    "        df = pd.read_csv(pth2)\n",
    "    else:\n",
    "        print('Something is wrong')\n",
    "    return df\n",
    "\n",
    "# Прочитаем файл, сохраним данные\n",
    "df = pth_load('toxic_comments.csv', '/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вызовем метод 'info()' и напечатаем несколько строк. Прочитаем одну строку целиком\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Прочитаем одну строку целиком\n",
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Напишем функцию для очистки текста\n",
    "def clear_text(text):\n",
    "    \"\"\"performs cleans the text\n",
    "\n",
    "    :param text: text to clear\n",
    "    :type text: object\n",
    "    \n",
    "    :rtype: object\n",
    "    :return: cleared text\n",
    "    \"\"\"\n",
    "    text = re.sub(r'[^a-z\\' ^0-9]', ' ', text)\n",
    "    #text = re.sub(r'[^a-z]', ' ', text)\n",
    "    clean_text = \" \".join(text.split())\n",
    "    \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переведем символы в нижний регистр\n",
    "df['lemm_text'] = df['text'].str.lower()\n",
    "\n",
    "# Обрежем текст ячеек от лишних символов\n",
    "df['lemm_text'] = df['lemm_text'].apply(lambda x: clear_text(x))\n",
    "\n",
    "#df['lemm_text'] = df['lemm_text'].str.slice(0, 512) # можно обрезать ячейки до 512 символов в случае необходимости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы ускорить лемматизацию, объединим ячейки и вызовем функцию лемматизации к объединенной строке. Проблема в том, что многие функции лемматизации, например Mystem, при каждом вызове загружается заново, сильно замедляя процесс. Также можно применить распараллеливание процесса.\n",
    "\n",
    "В данном случае мы используем WordNetLemmatizer, работающий с английским языком, но в рамках учебного процесса оставим этот метод.\n",
    "Данный метод был описан на странице https://itnan.ru/post.php?c=1&p=503420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сколько ячеек объединяем в одну\n",
    "batch_size = 1000\n",
    "\n",
    "text_batch = [list(df['lemm_text'])[i: i + batch_size] for i in range(0, len(df), batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:25<00:00,  6.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# Лемматизируем объединенные ячейки и разделим обратно на отдельные\n",
    "def checkExecTimeMystemOneText(texts):\n",
    "    \"\"\"performs lemmatization the text. first it combines the text for joint processing, at the end it separates\n",
    "\n",
    "    :param text: text to lemmatization\n",
    "    :type text: object\n",
    "    \n",
    "    :rtype: object\n",
    "    :return: lemmatized text\n",
    "    \"\"\"\n",
    "    #m = Mystem()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    lol = lambda lst, sz: [lst[i:i+sz] for i in range(0, len(lst), sz)]\n",
    "    txtpart = lol(texts, batch_size)\n",
    "    res = []\n",
    "    for txtp in txtpart:\n",
    "        alltexts = ' '.join([txt + ' brblm ' for txt in txtp])\n",
    "        \n",
    "        #words = m.lemmatize(alltexts)\n",
    "        words = [lemmatizer.lemmatize(w) for w in nltk.word_tokenize(alltexts)]\n",
    "        \n",
    "        doc = []\n",
    "        for txt in words:\n",
    "            if txt != '\\n' and txt.strip() != '':\n",
    "                if txt == 'brblm':\n",
    "                    res.append(doc)\n",
    "                    doc = []\n",
    "                else:\n",
    "                    doc.append(txt)\n",
    "                    \n",
    "        return res\n",
    "\n",
    "processed_texts = Parallel(n_jobs=-1)(delayed(checkExecTimeMystemOneText)(t) for t in tqdm(text_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   text       159571 non-null  object\n",
      " 1   toxic      159571 non-null  int64 \n",
      " 2   lemm_text  159571 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 3.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww he match this background colour i 'm see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i 'm really not trying to edit war it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i ca n't make any real suggestion on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  explanation why the edits made under my userna...  \n",
       "1  d'aww he match this background colour i 'm see...  \n",
       "2  hey man i 'm really not trying to edit war it ...  \n",
       "3  more i ca n't make any real suggestion on impr...  \n",
       "4  you sir are my hero any chance you remember wh...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получился вложенный список. Развернем верхний слой и объединим список в текст\n",
    "lemm_text = sum(processed_texts, [])\n",
    "\n",
    "# Удалим использованные переменные\n",
    "del text_batch\n",
    "del processed_texts\n",
    "\n",
    "for i in range(0, len(lemm_text), 1):\n",
    "    lemm_text[i] = \" \".join(lemm_text[i]).replace(' \\' ','\\'')\n",
    "\n",
    "# Сохраним в набор данных\n",
    "df['lemm_text'] = lemm_text\n",
    "del lemm_text\n",
    "\n",
    "# Проверим результат\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Соберем тренировочные и тестовые выборки, корпуса и таргеты\n",
    "train, test = train_test_split(df, test_size=0.5, random_state=SEED)\n",
    "\n",
    "corpus_train = train['lemm_text'].values.astype('U')\n",
    "corpus_test = test['lemm_text'].values.astype('U')\n",
    "\n",
    "target_train = train['toxic']\n",
    "target_test = test['toxic']\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим фичи на моделях. Для этого переведем текст в различные векторные выражения: мешок слов, N-граммы, TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер мешка: (79785, 112899)\n",
      "Размер мешка: (79786, 112899)\n"
     ]
    }
   ],
   "source": [
    "# Создадим мешок слов\n",
    "count_vect = CountVectorizer(dtype=np.float32, stop_words=stop_words)\n",
    "\n",
    "bow_train = count_vect.fit_transform(corpus_train) \n",
    "print(\"Размер мешка:\", bow_train.shape)\n",
    "\n",
    "bow_test = count_vect.transform(corpus_test) \n",
    "print(\"Размер мешка:\", bow_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер N-грамм: (79785, 1483795)\n",
      "Размер N-грамм: (79786, 1483795)\n"
     ]
    }
   ],
   "source": [
    "# Создадим N-граммы\n",
    "ngramm_vect = CountVectorizer(dtype=np.float32, stop_words=stop_words, ngram_range=(2, 2))\n",
    "\n",
    "n_gramm_train = ngramm_vect.fit_transform(corpus_train) \n",
    "print(\"Размер N-грамм:\", n_gramm_train.shape)\n",
    "\n",
    "n_gramm_test = ngramm_vect.transform(corpus_test) \n",
    "print(\"Размер N-грамм:\", n_gramm_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (79785, 112899)\n",
      "Размер матрицы: (79786, 112899)\n"
     ]
    }
   ],
   "source": [
    "# Создадим TF-IDF \n",
    "count_tfidf = TfidfVectorizer(stop_words=stop_words)\n",
    "\n",
    "tfidf_train = count_tfidf.fit_transform(corpus_train)\n",
    "print(\"Размер матрицы:\", tfidf_train.shape)\n",
    "\n",
    "tfidf_test = count_tfidf.transform(corpus_test)\n",
    "print(\"Размер матрицы:\", tfidf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучим различные модели машинного обучения на разных фичах: мешке слов, N-граммах, TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для уменьшения кода используем функцию\n",
    "def models_check(model, features_train, features_test, title):\n",
    "    \"\"\"trains the model and outputs the f1 metric\n",
    "\n",
    "    :param model: machine learning model\n",
    "    :type model: any machine learning model\n",
    "    :param features_train: data set with train features\n",
    "    :type features_train: csr_matrix or pd.DataFrame\n",
    "    :param features_test: data set with test features\n",
    "    :type features_test: csr_matrix or pd.DataFrame\n",
    "    :param title: machine learning model\n",
    "    :type title: description of models and features to display to the user\n",
    "    \n",
    "    \n",
    "    :rtype: trained machine learning model\n",
    "    :return: any machine learning model\n",
    "    \"\"\"\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = pd.Series(model.predict(features_test))\n",
    "    \n",
    "    print('Метрика F1 модели', title, '- {:.3f}'.format(f1_score(target_test, predictions)))\n",
    "    \n",
    "    return model, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1 модели DecisionTreeClassifier на мешке слов - 0.609\n"
     ]
    }
   ],
   "source": [
    "# Изучим дерево решений\n",
    "tree_classifier = DecisionTreeClassifier(random_state=SEED,\n",
    "                                         max_depth=13,\n",
    "                                         min_samples_leaf=4)\n",
    "\n",
    "\n",
    "# Вызовем дерево решений на мешке слов\n",
    "tree_bow_model, tree_bow_predictions = models_check(tree_classifier, \n",
    "                                                    bow_train, \n",
    "                                                    bow_test, \n",
    "                                                    'DecisionTreeClassifier на мешке слов')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1 модели DecisionTreeClassifier на N_граммах - 0.174\n"
     ]
    }
   ],
   "source": [
    "# Дерево решений на N_граммах\n",
    "tree_n_gramm_model, tree_n_gramm_predictions = models_check(tree_classifier, \n",
    "                                                            n_gramm_train, \n",
    "                                                            n_gramm_test, \n",
    "                                                            'DecisionTreeClassifier на N_граммах')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1 модели DecisionTreeClassifier на TF-IDF - 0.615\n"
     ]
    }
   ],
   "source": [
    "# Дерево решений на TF-IDF\n",
    "tree_tfidf_model, tree_tfidf_predictions = models_check(tree_classifier, \n",
    "                                                        tfidf_train, \n",
    "                                                        tfidf_test, \n",
    "                                                        'DecisionTreeClassifier на TF-IDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1 модели LGBMClassifier на мешке слов - 0.642\n"
     ]
    }
   ],
   "source": [
    "# Изучим модель градиентного бустинга\n",
    "lgbm_classifier = LGBMClassifier(random_state=SEED,\n",
    "                                 max_depth=13,\n",
    "                                 n_estimators=13,\n",
    "                                 learning_rate=1.0)\n",
    "\n",
    "\n",
    "# Вызовем модель градиентного бустинга на мешке слов\n",
    "lgbm_bow_model, lgbm_bow_predictions = models_check(lgbm_classifier, \n",
    "                                                    bow_train, \n",
    "                                                    bow_test, \n",
    "                                                    'LGBMClassifier на мешке слов')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1 модели LGBMClassifier на N_граммах - 0.240\n"
     ]
    }
   ],
   "source": [
    "# Модель градиентного бустинга на N_граммах\n",
    "lgbm_n_gramm_model, lgbm_n_gramm_predictions = models_check(lgbm_classifier, \n",
    "                                                            n_gramm_train, \n",
    "                                                            n_gramm_test, \n",
    "                                                            'LGBMClassifier на N_граммах')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1 модели LGBMClassifier на TF-IDF - 0.673\n"
     ]
    }
   ],
   "source": [
    "# Модель градиентного бустинга на TF-IDF\n",
    "lgbm_tfidf_model, lgbm_tfidf_predictions = models_check(lgbm_classifier, \n",
    "                                                        tfidf_train, \n",
    "                                                        tfidf_test, \n",
    "                                                        'LGBMClassifier на TF-IDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1 модели LogisticRegression на мешке слов - 0.752\n"
     ]
    }
   ],
   "source": [
    "# Изучим модель логистической регрессии\n",
    "log_reg_model = LogisticRegression(random_state=SEED, \n",
    "                                   max_iter=1000)\n",
    "\n",
    "\n",
    "# Вызовем модель градиентного бустинга на мешке слов\n",
    "log_reg_bow_model, log_reg_bow_predictions = models_check(log_reg_model, \n",
    "                                                          bow_train, \n",
    "                                                          bow_test, \n",
    "                                                          'LogisticRegression на мешке слов')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1 модели LogisticRegression на N_граммах - 0.321\n"
     ]
    }
   ],
   "source": [
    "# Модель градиентного бустинга на N_граммах\n",
    "log_reg_n_gramm_model, log_reg_n_gramm_predictions = models_check(log_reg_model, \n",
    "                                                          n_gramm_train, \n",
    "                                                          n_gramm_test, \n",
    "                                                          'LogisticRegression на N_граммах')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1 модели LogisticRegression на TF-IDF - 0.710\n"
     ]
    }
   ],
   "source": [
    "# Модель градиентного бустинга на TF-IDF\n",
    "log_reg_tfidf_model, log_reg_tfidf_predictions = models_check(log_reg_model, \n",
    "                                                              tfidf_train, \n",
    "                                                              tfidf_test, \n",
    "                                                              'LogisticRegression на TF-IDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшую метрику F1 показала модель логистической регрессии, обучанная на мешке слов. Она же единственная, достигнувшая порога в 0.75.\n",
    "\n",
    "Логистическая регрессия лучше всего обучилась на мешке слов и TF-IDF. Аналогично модель дерево решений, и градиентного бустинга. Но модель градиентного бустинга обучилась на TF-IDF лучше, чем на мешке слов. Все рассматриваемые модели на N_граммах показали худшие результаты."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
